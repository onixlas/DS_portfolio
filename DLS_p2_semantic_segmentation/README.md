# Задача

![](https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Typical_cnn.png/800px-Typical_cnn.png 'Aphex34')


В данном проекте нам предстоит решить задачу сегментации медицинских снимков. В нашем распоряжении датасет [*ADDI project*](https://www.fc.up.pt/addi/ph2%20database.html). В нём содержатся фотографии различных поражений кожи: меланомы и родинок. Однако мы будем заниматься не классификацией, а сегментацией изображений, т.е. разделением изображений на несколько сегментов для упрощения последующего анализа и обработки. Проще говоря, нам необходимо обучить модель, которая сможет для каждого пикселя исходного изображения определить: изображена на нём родинка, либо просто участок кожи.

Попробуем создать и обучить две модели для семантической сегментации:
* [*SegNet*](https://arxiv.org/pdf/1511.00561.pdf), часто используемую на практике модель, базирующуюся на архитектуре *VGG16* для формирования энкодера;
* [*U-Net*](https://arxiv.org/pdf/1505.04597.pdf), модель, изначально создававшуюся и оптимизированную для семантической сегментации медицинских изображений.

В качестве эксперимента реализуем также несколько модификаций оригинальной модели *U-Net*: заменим некоторые слои на их аналоги и посмотрим, скажется ли это на результате.

Также попробуем реализовать несколько функций потерь, чтобы оценить, насколько они влияют на конечный результат сегментации.

# Вывод

В данном проекте мы решали задачу сегментации медицинских снимков. В нашем распоряжении датасет [*ADDI project*](https://www.fc.up.pt/addi/ph2%20database.html). В нём содержатся фотографии различных поражений кожи: меланомы и родинок.

Мы начали с того, что реализовали модель на основе архитектуры [*SegNet*](https://arxiv.org/pdf/1511.00561.pdf), в качестве функции потерь использовалась бинарную кросс-энтропию. Мы также реализовали несколько дополнительных функций потерь, чтобы проверить, как они скажутся на обучаемости модели.

Каждая модель обучалась в течение 40 эпох с оптимизатором *AdamW*. В качестве метрики мы использовали [коэффициент Жаккара *(IoU)*](https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D1%8D%D1%84%D1%84%D0%B8%D1%86%D0%B8%D0%B5%D0%BD%D1%82_%D0%96%D0%B0%D0%BA%D0%BA%D0%B0%D1%80%D0%B0).

Сведём данные по значениям метрики IoU на последних эпохах обучения для всех функций потерь.

| Модель | Функция потерь | IoU (train) |IoU (valid) |
|---------|----|---|---|
| SegNet | BCE loss | 0.8291 |0.7981 |
| SegNet | Dice loss | 0.7965 |0.7892 |
| SegNet | Focal loss | 0.8061 |0.7680 |
| SegNet | WSR loss | 0.7587 |0.8007 |

Видно, что для всех функций потерь удалось достичь достаточно неплохих значений метрики *IoU*. Наилучшие результаты показала модель с функцией потерь WSR loss, однако результаты в целом различаются не очень сильно.

Из построенных в рамках проекта графиков видно, что 40 эпох хватило, чтобы достичь сходимости для всех функций потерь. При этом стоит отметить, что для функции потерь *Dice loss* значения на графиках сходились стабильнее всего.

Также мы обучили несколько моделей с различными вариациями архитектуры [*U-Net*](https://arxiv.org/abs/1505.04597).

Первую модель мы реализовали в соответствии с оригинальной статьёй. Для пулинга (уменьшения размера изображений внутри сети) использовался _MaxPooling_, для апсамплинга (увеличения размера изображений внутри сети) - слои с обратной свёрткой _(ConvTranspose)_.

Во второй модели для пулинга также использовался _MaxPooling_, а для апсмаплинга был применён _nearest-neighbor Upsampling_.

В третьей модели для пулинга были применены свёрточные слои.

Все три модели обучались с функцией потерь BCE. Для каждой модели рассчитывался коэффициент _IoU_.

Сведём результаты экспериментов с U-Net в единую таблицу.

| Модель | Функция потерь | IoU (train) |IoU (valid) |
|---------|----|---|---|
| U-Net | BCE loss | 0.8668 |0.8016 |
| U-Net + upsampling | BCE loss | 0.8197 |0.8299 |
| U-Net + convpool | BCE loss | 0.7938 |0.8327 |

Видно, что в рамках наших экспериментов значения метрики _IoU_ для различных модификаций архитектуры _U-Net_ несколько выше, чем для модели _SegNet_. Наилучшего значения метрики на валидации удалось добиться при использовании свёрточного пуллинга.

Модели на основе _U-Net_ показывают достаточно высокие значения метрики *IoU*, но они сходятся несколько хуже моделей на основе архитектуры *SegNet*. Наилучшую сходимость показала модель со свёрточным пуллингом.

Из проведённых экспериментов видно, что на результаты модели оказывают существенное влияние различные факторы, в том числе выбор фукнции потерь и нюансов архитектуры. При их выборе следует учитывать несколько факторов: наилучшие значения метрики, стабильность сходимости модели, скорость обучения (количество обучаемых параметров модели). В рамках нашей задачи, если предположить, что заказчику важнее всего значение метрики *IoU*, наилучший результат продемонстрировала модель на основе архитектуры *U-Net* со свёрточным пуллингом.

